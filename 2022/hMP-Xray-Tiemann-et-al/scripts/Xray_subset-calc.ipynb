{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "everyday-quebec",
   "metadata": {},
   "source": [
    "# Imports & General settings\n",
    "change paths for your environments and folder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "endangered-thomson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 µs, sys: 4 µs, total: 25 µs\n",
      "Wall time: 30.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Standard library imports\n",
    "import glob\n",
    "import logging as log\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "import urllib.request\n",
    "\n",
    "# Third party imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worth-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger configuration\n",
    "\n",
    "log_message=\"verbose\"\n",
    "if log_message==\"verbose\":\n",
    "    log.basicConfig(\n",
    "        format='%(levelname)s:%(message)s',\n",
    "        datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "        level=log.INFO\n",
    "    )\n",
    "elif log_message==\"debug\":\n",
    "    log.basicConfig(\n",
    "        format='%(levelname)s:%(message)s',\n",
    "        datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "        level=log.WARNING\n",
    "    )\n",
    "else:\n",
    "    log.basicConfig(\n",
    "        format='%(levelname)s:%(message)s',\n",
    "        datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "        level=log.ERROR\n",
    "    )\n",
    "\n",
    "logger = log.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stopped-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General settings\n",
    "\n",
    "saving_dir_flag = 'projects/Xray_calc'\n",
    "\n",
    "\n",
    "myhost = os.uname()[1]\n",
    "if myhost.startswith('fend'):\n",
    "    \n",
    "    # Cluster where ROSETTA calculations are running\n",
    "    basepath = ''\n",
    "\n",
    "    path_to_rosetta_dir = '_path_to_software_/Rosetta_2021_Aug_c7009b3'\n",
    "    path_to_prism_exec_dir = '_path_to_software_/PRISM_tools/rosetta_stability-v0.1.1/software/'\n",
    "\n",
    "    rosetta_working_dir = os.path.join(basepath, saving_dir_flag)\n",
    "    os.makedirs(rosetta_working_dir, exist_ok=True)\n",
    "\n",
    "    # Local application imports\n",
    "    try:\n",
    "        sys.path.insert(1, os.path.join(path_to_prism_exec_dir, 'scripts'))\n",
    "        from pdb_to_prism import download_pdb, rosetta_energy_to_prism\n",
    "    except (ModuleNotFoundError, ImportError) as e:\n",
    "        logger.error(\"{} fileure\".format(type(e)))\n",
    "        print(e)\n",
    "    else:\n",
    "        logger.info(\"Import succeeded\")\n",
    "\n",
    "else:\n",
    "    \n",
    "    # Cluster where GEMME calculations are running\n",
    "    basepath = ''\n",
    "\n",
    "    path_to_gemme_exec = os.path.join(basepath, 'dev/repos/prism_gemme_pipeline/frag_pipeline.py')\n",
    "    path_to_python = os.path.join(basepath, 'dev/miniconda3/bin/python')\n",
    "\n",
    "    gemme_working_dir = os.path.join(basepath, saving_dir_flag)\n",
    "    os.makedirs(gemme_working_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dental-preliminary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target list to run on\n",
    "\n",
    "target_list = [\n",
    "    ['P08100', 'OPSD', ['GPCR', 'A'], ['4zwj-A']],\n",
    "    ['P11166', 'GTR1', ['Transporter', 'SLC2'], ['6tha-A']],\n",
    "    ['O15118', 'NPC1', ['Transporter', 'SLC65'], ['5u74-A', '6w5s-A']],\n",
    "    ['Q99835', 'SMO', ['', ''], ['5l7d-A']],\n",
    "    ['P31213', 'S5A2', ['', ''], ['7bw1-A']],\n",
    "    ['P41181', 'AQP2', ['', ''], ['4nef-A']],\n",
    "    ['Q9ULV1', 'FZD4', ['', ''], ['6bd4-A']],\n",
    "    ['P16615', 'AT2A2', ['', ''], ['7bt2-A']],\n",
    "    ['P17787', 'ACHB2', ['', ''], ['5kxi-C']],\n",
    "    ['P43681', 'ACHA4', ['IonChannel', 'ligand'], ['5kxi-A', '6cnj-A', '6usf-A']],\n",
    "    ['Q9H221', 'ABCG8', ['', ''], ['5do7-D']],\n",
    "    ['Q9H3H5', 'GPT', ['Enzyme', 'Glycosyltransferase'], ['6fm9-A', '6bw6-B']],\n",
    "    ['P32245', 'MC4R', ['', ''], ['6w25-A']],\n",
    "    ['P29033', 'CXB2', ['', ''], ['2zw3-A']],\n",
    "    ['Q8N5M9', 'JAGN1', ['', ''], ['6wvd-A']],\n",
    "    ['Q9H222', 'ABCG5', ['', ''], ['5do7-A']],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-shaft",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hundred-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_by_uniprot_fasta(keyword):\n",
    "    # extract information from uniprot\n",
    "    url_base = \"https://www.uniprot.org/uniprot/\"\n",
    "    search_params = \"?query=reviewed:yes\" +\\\n",
    "        \"+AND+accession:\" + keyword\n",
    "    return_params = \"+&format=tab&columns=id,sequence,organism,entry%20name\"\n",
    "    url = url_base + search_params + return_params\n",
    "\n",
    "    data_array = []\n",
    "    for line in urllib.request.urlopen(url):\n",
    "        line = line.decode('utf-8')\n",
    "        unprocessed = line[:-1].split('\\t')\n",
    "        data_array.append(unprocessed)\n",
    "\n",
    "    return data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naval-electric",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(input_pdb, working_dir, protein_id, mode='fullrun', chain='A', partition='sbinlab', mutfile=None, mut_mode='all', \n",
    "                 relax_xml_file=None, outflag='', cartesian=False, scale=1.0):\n",
    "\n",
    "    submit_script = os.path.join(working_dir, f'submit_{protein_id}.sh')\n",
    "    with open(submit_script, 'w') as fp:\n",
    "        fp.write(('#!/bin/sh \\n'\n",
    "                f'#SBATCH --job-name={protein_id} \\n'\n",
    "                '#SBATCH --time=24:00:00 \\n'\n",
    "                '#SBATCH --array=1 \\n'\n",
    "                f'#SBATCH --partition={partition} \\n'))\n",
    "\n",
    "        if outflag!='':\n",
    "            out_dir = os.path.join(working_dir, f'run_{outflag}' )\n",
    "        else:\n",
    "            out_dir = os.path.join(working_dir, f'run' )\n",
    "        input_args = [\n",
    "            '--structure', input_pdb,\n",
    "            '--mutate_mode', mut_mode,\n",
    "            '--outputpath', out_dir,\n",
    "            '--chainid', chain,\n",
    "            '--mode', mode,\n",
    "            '--is_membrane', 'True',\n",
    "            '--mp_calc_span_mode', 'DSSP',\n",
    "            '--mp_align_ref', f'{protein_id}_{chain}',\n",
    "            '--mp_prep_align_mode', 'OPM',\n",
    "            '--slurm_partition', partition,\n",
    "            '--scale', f\"{scale}\",\n",
    "            '--overwrite_path', 'True',\n",
    "                     ]\n",
    "        if cartesian:\n",
    "            input_args.append(f'--mp_cart_ddg 1')\n",
    "        \n",
    "        if mutfile:\n",
    "            input_args.append(f'--mutations {mutfile}')\n",
    "            \n",
    "        path_to_pipeline = os.path.join(path_to_prism_exec_dir, 'rosetta_ddG_pipeline')\n",
    "        command = f\"python {os.path.join(path_to_pipeline, 'run_pipeline.py')}\", \" \".join(input_args)\n",
    "        \n",
    "        fp.write(f'{\" \".join(command)} \\n')\n",
    "    return submit_script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-handbook",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "# Calculate GEMME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demonstrated-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemme_output = os.path.join(gemme_working_dir, 'prism_gemme')\n",
    "os.makedirs(gemme_output, exist_ok=True)\n",
    "gemme_workdir = os.path.join(gemme_working_dir, 'gemme')\n",
    "os.makedirs(gemme_workdir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "timely-welcome",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for index, target in enumerate(target_list):\n",
    "    \n",
    "    accessionID, accessionName, classlist, pdblist = target\n",
    "    result_gemme_subdir = os.path.join(gemme_output, accessionID[0:2], accessionID[2:4], accessionID[4:6])\n",
    "    final_gemme_prism = os.path.join(result_gemme_subdir, f'prism_gemme_XXX_{accessionID}.txt')\n",
    "    if os.path.isfile(final_gemme_prism):\n",
    "        logger.info(f'{accessionID} already calculated')\n",
    "    else:\n",
    "        gemme_workdir_target = os.path.join(gemme_workdir, accessionID)\n",
    "        os.makedirs(gemme_workdir_target, exist_ok=True)\n",
    "        gemme_workdir_input = os.path.join(gemme_workdir_target, 'input')\n",
    "        os.makedirs(gemme_workdir_input, exist_ok=True)\n",
    "        gemme_run_dir = os.path.join(gemme_workdir_target, 'run')\n",
    "\n",
    "        def get_fasta(uniprot_id, run_dir):\n",
    "            os.makedirs(run_dir, exist_ok=True)cd p\n",
    "            fasta_file = os.path.join(run_dir, f'{uniprot_id}.fasta')\n",
    "            extracted = extract_by_uniprot_fasta(uniprot_id)\n",
    "            with open(fasta_file, 'w') as fp:\n",
    "                fp.write(f'>sp|{accessionID}|{extracted[1][3]}\\n')\n",
    "                fp.write(extracted[1][1])\n",
    "            return fasta_file\n",
    "\n",
    "        fasta_file = get_fasta(accessionID, gemme_workdir_input)\n",
    "\n",
    "        submitter = f'{path_to_python} {path_to_gemme_exec} -s {fasta_file} -o {gemme_run_dir} '\n",
    "        logger.info(f'Submitting {accessionID}: {submitter}')\n",
    "        #pipes = subprocess.Popen(submitter, shell=True, cwd=gemme_workdir_target,stdout=subprocess.PIPE,stderr=subprocess.PIPE,)\n",
    "        #std_out, std_err = pipes.communicate()\n",
    "        logger.info(f'Execution of {accessionID} done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "residential-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for index, target in enumerate(target_list):\n",
    "    \n",
    "    accessionID, accessionName, classlist, pdblist = target\n",
    "    result_gemme_subdir = os.path.join(gemme_output, accessionID[0:2], accessionID[2:4], accessionID[4:6])\n",
    "    final_gemme_prism = os.path.join(result_gemme_subdir, f'prism_gemme_XXX_{accessionID}.txt')\n",
    "    if os.path.isfile(final_gemme_prism):\n",
    "        logger.info(f'{accessionID} already calculated')\n",
    "    else:\n",
    "        gemme_workdir_target = os.path.join(gemme_workdir, accessionID)\n",
    "        os.makedirs(gemme_workdir_target, exist_ok=True)\n",
    "        gemme_workdir_input = os.path.join(gemme_workdir_target, 'input')\n",
    "        os.makedirs(gemme_workdir_input, exist_ok=True)\n",
    "        gemme_run_dir = os.path.join(gemme_workdir_target, 'run')\n",
    "        os.makedirs(gemme_run_dir, exist_ok=True)\n",
    "\n",
    "        os.makedirs(result_gemme_subdir, exist_ok = True)\n",
    "        tmp_prism_gemme = glob.glob(os.path.join(gemme_run_dir, 'gemme_scores', f'prism_gemme_*'))[0]\n",
    "        shutil.copyfile(tmp_prism_gemme, final_gemme_prism)\n",
    "       # shutil.rmtree(gemme_workdir_target, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-childhood",
   "metadata": {},
   "source": [
    "# Calculate ∆∆Gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interesting-repeat",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#prepare ddG calculation directory\n",
    "\n",
    "rosetta_dir = os.path.join(rosetta_working_dir, 'rosetta')\n",
    "os.makedirs(rosetta_dir, exist_ok=True)\n",
    "shared_dir = os.path.join(rosetta_working_dir, 'shared')\n",
    "rosetta_prism = os.path.join(rosetta_working_dir, 'prism_rosetta')\n",
    "os.makedirs(rosetta_prism, exist_ok=True)\n",
    "\n",
    "for targetID, target in enumerate(target_list):\n",
    "    target_uniprot = target[0]\n",
    "    target_work_dir = os.path.join(rosetta_dir, target_uniprot)\n",
    "    os.makedirs(target_work_dir, exist_ok=True)\n",
    "    target_input_dir = os.path.join(target_work_dir, 'input')\n",
    "    os.makedirs(target_input_dir, exist_ok=True)\n",
    "    target_calc_dir = os.path.join(target_work_dir, 'calc')\n",
    "    os.makedirs(target_calc_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-latin",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## Manual obtain and check structures\n",
    "execute and then check & clean the script manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intense-adult",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PDB structure '4zwj'...\n",
      "Downloading PDB structure '6tha'...\n",
      "Downloading PDB structure '5u74'...\n",
      "Downloading PDB structure '5l7d'...\n",
      "Downloading PDB structure '7bw1'...\n",
      "Downloading PDB structure '4nef'...\n",
      "Downloading PDB structure '6bd4'...\n",
      "Downloading PDB structure '7bt2'...\n",
      "Downloading PDB structure '5kxi'...\n",
      "Downloading PDB structure '5kxi'...\n",
      "Downloading PDB structure '5do7'...\n",
      "Downloading PDB structure '6fm9'...\n",
      "Downloading PDB structure '6w25'...\n",
      "Downloading PDB structure '2zw3'...\n",
      "Downloading PDB structure '6wvd'...\n",
      "Downloading PDB structure '5do7'...\n"
     ]
    }
   ],
   "source": [
    "for targetID, target in enumerate(target_list):\n",
    "    target_uniprot = target[0]\n",
    "    target_work_dir = os.path.join(rosetta_dir, target_uniprot)\n",
    "    target_input_dir = os.path.join(target_work_dir, 'input')\n",
    "    target_pdbID = target[3][0].split('-')[0]\n",
    "    download_pdb(target_pdbID, output_dir=target_input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "regional-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "for targetID, target in enumerate(target_list):\n",
    "    target_uniprot = target[0]\n",
    "    target_work_dir = os.path.join(rosetta_dir, target_uniprot)\n",
    "    target_input_dir = os.path.join(target_work_dir, 'input')\n",
    "    target_pdbID = target[3][0].split('-')[0]\n",
    "    target_pdbchain = target[3][0].split('-')[1]\n",
    "    pdb_input = os.path.join(target_input_dir, f\"{target_pdbID.lower()}.pdb\")\n",
    "    pdb_clean = os.path.join(target_input_dir, f'{target_pdbID.lower()}_{target_pdbchain}-clean.pdb')\n",
    "    shutil.copy(pdb_input, pdb_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-tunisia",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## make input files (rosetta-pdb and mutfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thermal-performer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:Execution of 0 done\n",
      "INFO:Execution of 1 done\n",
      "INFO:Execution of 2 done\n",
      "INFO:Execution of 3 done\n",
      "INFO:Execution of 4 done\n",
      "INFO:Execution of 5 done\n",
      "INFO:Execution of 6 done\n",
      "INFO:Execution of 7 done\n",
      "INFO:Execution of 8 done\n",
      "INFO:Execution of 9 done\n",
      "INFO:Execution of 10 done\n",
      "INFO:Execution of 11 done\n",
      "INFO:Execution of 12 done\n",
      "INFO:Execution of 13 done\n",
      "INFO:Execution of 14 done\n",
      "INFO:Execution of 15 done\n"
     ]
    }
   ],
   "source": [
    "execution_lists = []\n",
    "for targetID, target in enumerate(target_list):\n",
    "    target_uniprot = target[0]\n",
    "    target_work_dir = os.path.join(rosetta_dir, target_uniprot)\n",
    "    target_input_dir = os.path.join(target_work_dir, 'input')\n",
    "    target_pdbID = target[3][0].split('-')[0]\n",
    "    target_pdbchain = target[3][0].split('-')[1]\n",
    "    \n",
    "    pdb_input = os.path.join(target_input_dir, f'{target_pdbID.lower()}_{target_pdbchain}-clean.pdb')\n",
    "    merged_prism_file = os.path.join(shared_dir, f'prism_merged_XXX_{target_uniprot}_MP.txt')\n",
    "    script = os.path.join(path_to_prism_exec_dir, 'scripts/prism2mutfile.py')\n",
    "    func = f'python {script} {merged_prism_file} -o {target_input_dir} -i {pdb_input} -r True'\n",
    "    pipes = subprocess.Popen(func, shell=True, cwd=target_input_dir,stdout=subprocess.PIPE,stderr=subprocess.PIPE,)\n",
    "    std_out, std_err = pipes.communicate()\n",
    "    logger.info(f'Execution of {targetID} done')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-driver",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fallen-device",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/sbinlab/software/Rosetta_2021_Aug_c7009b3/database'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set correct environment\n",
    "os.environ['ddG_pipeline'] = os.path.join(path_to_prism_exec_dir, 'rosetta_ddG_pipeline')\n",
    "os.getenv('ddG_pipeline')\n",
    "os.environ['Rosetta_main_path'] = os.path.join(path_to_rosetta_dir, 'source')\n",
    "os.getenv('Rosetta_main_path')\n",
    "os.environ['Rosetta_database_path'] = os.path.join(path_to_rosetta_dir, 'database')\n",
    "os.getenv('Rosetta_database_path')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silent-norfolk",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_lists = []\n",
    "for targetID, target in enumerate(target_list):\n",
    "    target_uniprot = target[0]\n",
    "    target_work_dir = os.path.join(rosetta_dir, target_uniprot)\n",
    "    target_input_dir = os.path.join(target_work_dir, 'input')\n",
    "    target_calc_dir = os.path.join(target_work_dir, 'calc')\n",
    "    target_pdbID = target[3][0].split('-')[0]\n",
    "    target_pdbchain = target[3][0].split('-')[1]\n",
    "\n",
    "    pdb_input = os.path.join(target_input_dir, f'{target_pdbID.lower()}_{target_pdbchain}-clean_renum.pdb')\n",
    "    mutfile_input = os.path.join(target_input_dir, 'mutfile_all')\n",
    "\n",
    "    \n",
    "    if targetID%3 == 0:\n",
    "        partition = 'sbinlab'\n",
    "    elif targetID%3 == 1:\n",
    "        partition = 'sbinlab_ib'\n",
    "    else:\n",
    "        partition = 'sbinlab_ib2'\n",
    "    \n",
    "    exect = run_pipeline(pdb_input, target_calc_dir, target_pdbID, mode='fullrun',#'relax' #'create' #'fullrun', #ddg_calculation #proceed\n",
    "                         chain=target_pdbchain, partition=partition,\n",
    "                         mutfile=mutfile_input, mut_mode='mut_file',\n",
    "                         outflag='cart', cartesian=True\n",
    "                        )\n",
    "    execution_lists.append(exect)\n",
    "\n",
    "\n",
    "#Submit (switch with care....)\n",
    "do_execute=True\n",
    "if do_execute:\n",
    "    for submit in execution_lists:\n",
    "        subprocess.call(f'sbatch {submit}', shell=True, cwd=rosetta_dir)\n",
    "        logger.info(submit)\n",
    "else:\n",
    "    logger.warning(\"executing set to false - only switch on when you know what you're doing!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proprietary-hamilton",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "## check if ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "for targetID, target in enumerate(target_list):\n",
    "    target_uniprot = target[0]\n",
    "    target_work_dir = os.path.join(rosetta_dir, target_uniprot)\n",
    "    target_input_dir = os.path.join(target_work_dir, 'input')\n",
    "    target_calc_dir = os.path.join(target_work_dir, 'calc')\n",
    "    target_pdbID = target[3][0].split('-')[0]\n",
    "    target_pdbchain = target[3][0].split('-')[1]\n",
    "    logger.info(target_uniprot)\n",
    "    prism_file = os.path.join(target_calc_dir, 'run_cart', 'output', f'prism_rosetta_XXX_{target_pdbID}_{target_pdbchain}-clean_renum.txt')\n",
    "    if os.path.isfile(prism_file):\n",
    "        pdb_file = glob.glob(os.path.join(target_calc_dir, 'run_cart', 'output', f'*_final.pdb'))[0]\n",
    "        logger.info(f\"Calculation for {target_uniprot} ({target[1]}) finished\")\n",
    "        final_target_rosetta_prism_dir = os.path.join(rosetta_prism, target_uniprot[0:2], target_uniprot[2:4], target_uniprot[4:6])\n",
    "        final_target_rosetta_prism = os.path.join(final_target_rosetta_prism_dir, f'prism_rosetta_XXX_{target_uniprot}_{target_pdbID}_{target_pdbchain}_cartesian.txt')\n",
    "        final_target_rosetta_pdb_prism = os.path.join(final_target_rosetta_prism_dir, f'prism_rosettapdb_XXX_{target_uniprot}_{target_pdbID}_{target_pdbchain}_cartesian.txt')\n",
    "\n",
    "        if os.path.isfile(final_target_rosetta_prism):\n",
    "            logger.info(f'{target_uniprot} already copied')\n",
    "        else:\n",
    "            os.makedirs(final_target_rosetta_prism_dir, exist_ok = True)\n",
    "            shutil.copyfile(prism_file, final_target_rosetta_prism)\n",
    "            rosetta_energy_to_prism(pdb_file, final_target_rosetta_pdb_prism, target_pdbID, target_pdbchain, final_target_rosetta_prism_dir, uniprot_id=target_uniprot)\n",
    "            #shutil.copyfile(pdb_file, final_target_rosetta_pdb)\n",
    "            logger.info(f'{target_uniprot} now copied')\n",
    "    else:\n",
    "        logger.info(f\"Calculation for {target_uniprot} ({target[1]}) not finished\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-compression",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
