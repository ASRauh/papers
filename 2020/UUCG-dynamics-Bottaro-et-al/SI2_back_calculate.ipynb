{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back-calculate experimental data from structure\n",
    "\n",
    "Here we back-calcuate the experimental quantities from PDB structures and trjactories.\n",
    "The experimental datasets are\n",
    "- Dataset A: Exact eNOEs (Nichols et al. (2018b)), consisting in 62 bidirectional exact NOE, 177 unidirectional eNOE and 77 generic normalized eNOE (gn-125 eNOE). This dataset alone was used to determine the structure of the UUCG tetraloop with PDB accession codes 6BY4 and 6BY5.In addition to the original dataset we added 1 new eNOE and 6 new gn-eNOEs:\n",
    "\n",
    "```\n",
    "NEW bidirectional eNOE\n",
    "C8_H4';G10_H8  5.77 0.577\n",
    "\n",
    "New gn-eNOE, used as lower-bound distances \n",
    " C8_H5;G10_H1'  5.8 0.58 \n",
    " C8_H5;G10_H8 5.87 0.587  \n",
    " C8_H2';G10_H8 7.06 0.706\n",
    " C8_H3';G9_H8 5.78 0.578 \n",
    " C8_H2';G9_H8 5.92 0.592 \n",
    " C8_H1';G10_H4' 5.28 0.528 \n",
    " C8_H2';G9_H2' 4.62 0.462 \n",
    "```\n",
    "\n",
    "- Dataset B. Taken from the study “High-Resolution NMR Structure of a RNA model system: the 14mer cUUCGg tetraloop hairpin RNA“ and corresponding PDB structure 2KOC. \n",
    "- Dataset C. 38 (RDC1) plus 13 (RDC2) residual dipolar couplings. These RDCs have been used in conjunction with MD simulations to obtain a dynamic ensemble of the UUCG tetraloop. Borkar et al. (2017).\n",
    "\n",
    "- Dataset D. 91 solvent paramagnetic resonance enhancement (sPRE) measurements from Hartlmüller et al. (2017).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset A\n",
    "\n",
    "## bidirectional exact noes (eNOE). \n",
    "From the original list of 72 distances, 10 datapoints were removed, corresponding to distances between H41-H42, H21-H22, H5'-H5'' and H5-H6 protons in the same nucleotide. 6 URA H2' 7 URA H6 bi-dir 4.56 and 6 URA H2' 6 URA H6 bi-dir 3.83 are duplicated and were also removed. The experimental error was set to 10% of the eNOE. For all NOE data used here we use the standard $^{-6}$ averaging, i.e. $\\text{NOE}_{\\text{CALC}} = (\\sum_i w_i r_i^{-6})^{-1/6}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidePrompt": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Found 63 pairs out of 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbottaro/anaconda3/envs/py36/lib/python3.6/site-packages/mdtraj/formats/pdb/pdbfile.py:196: UserWarning: Unlikely unit cell vectors detected in PDB file likely resulting from a dummy CRYST1 record. Discarding unit cell vectors.\n",
      "  warnings.warn('Unlikely unit cell vectors detected in PDB file likely '\n",
      "/home/sbottaro/anaconda3/envs/py36/lib/python3.6/site-packages/mdtraj/core/trajectory.py:419: UserWarning: top= kwarg ignored since file contains topology information\n",
      "  warnings.warn('top= kwarg ignored since file contains topology information')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Found 63 pairs out of 63\n",
      "# Found 63 pairs out of 63\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# helper functions, subsititute strings. This is because the name of hydrogens is a mess\n",
    "alt = {\"H2'\":\"1H2'\",\"H5''\":\"2H5'\",\"H5'\":\"1H5'\",\"HO2'\":\"2HO'\",\"H5\\\"\":\"2H5'\"}\n",
    "def sub(ss):\n",
    "    at = ss.split(\"_\")[1]\n",
    "    if(at in alt):\n",
    "        at = alt[at]\n",
    "    return ss.split(\"_\")[0] + \"-\" + at\n",
    "\n",
    "# read experimental datafile and returns a list of labels and experimental values\n",
    "def read_exp(f_exp):\n",
    "    \n",
    "    labels = []\n",
    "    vals = []\n",
    "    fh = open(f_exp)\n",
    "    \n",
    "    for line in fh:\n",
    "        if(\"#\" not in line):\n",
    "            r1 = line.split()[0].split(\";\")[0]\n",
    "            r2 = line.split()[0].split(\";\")[1]\n",
    "            v1 = np.sort([r1,r2])\n",
    "            qq = v1[0] +\"/\"+ v1[1]\n",
    "            if(qq in labels):\n",
    "                print(\"# DUPLICATE. Skipping data..\"),\n",
    "                print(qq,vals[labels.index(qq)], line),\n",
    "            else:\n",
    "                vals.append([float(line.split()[1]),float(line.split()[2])])\n",
    "                labels.append(qq)\n",
    "            \n",
    "    fh.close()\n",
    "    return labels,vals\n",
    "\n",
    "\n",
    "# find indeces in topology corresponding to labels in experimental datafile\n",
    "def get_idxs(labels,top):\n",
    "    \n",
    "    atoms = []\n",
    "    for atom in top.atoms:\n",
    "        aa = str(atom).split(\"-\")[1]\n",
    "        if(aa in alt): aa = alt[aa]\n",
    "        atoms.append(\"%s-%s\" % (str(atom).split(\"-\")[0],aa))\n",
    "    pairs = []\n",
    "    for el in labels:\n",
    "        ss = el.split(\"/\")\n",
    "        at1= sub(ss[0])\n",
    "        at2 = sub(ss[1])\n",
    "        if(at1 in atoms and at2 in atoms):\n",
    "            pairs.append([atoms.index(at1),atoms.index(at2)])\n",
    "        else:\n",
    "            print(\"# Warning: Either %s or %s are missing\" % (at1,at2)) \n",
    "            return 0\n",
    "    print(\"# Found %d pairs out of %d\" % (len(pairs),len(labels)))\n",
    "    return np.array(pairs)\n",
    "\n",
    "\n",
    "def write(data,fname):\n",
    "    fh = open(fname,\"w\")\n",
    "    stri = \"\"\n",
    "    for j in range(data.shape[0]):\n",
    "        stri += \"%10d \"% j \n",
    "        stri += \" \".join([\"%10.4e\" % data[j,k] for k in range(data.shape[1])])\n",
    "        stri += \"\\n\"\n",
    "    fh.write(stri)\n",
    "    fh.close()\n",
    "\n",
    "    \n",
    "#######################\n",
    "\n",
    "    \n",
    "import mdtraj as md\n",
    "\n",
    "top = \"data/PDB/2koc_gmx.pdb\"\n",
    "traj = \"data/traj_temp_f_0.xtc\"\n",
    "labels,vals = read_exp(\"data/exp/set_A/eNOE.exp.dat\")\n",
    "\n",
    "md_trj = md.load(traj,top=top)\n",
    "pairs = get_idxs(labels,md_trj.topology)\n",
    "# convert to Angstrom\n",
    "dists_md = 10*md.compute_distances(md_trj,pairs)\n",
    "# write to file \n",
    "write(dists_md,\"data/calc/set_A/eNOE.calc.dat\")\n",
    "\n",
    "pdbs = [\"2koc\",\"6by5\"]\n",
    "dists_pdbs = []\n",
    "for  p in pdbs:\n",
    "    top = \"data/PDB/%s.pdb\" % p \n",
    "    traj = \"data/PDB/%s.pdb\" % p \n",
    "    md_trj = md.load(traj,top=top)\n",
    "    pairs = get_idxs(labels,md_trj.topology)\n",
    "    dists = 10.0*md.compute_distances(md_trj,pairs)\n",
    "    write(dists,\"data/calc/set_A/%s.eNOE.calc.dat\" %p)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unidirectional eNOE\n",
    "From the original list of 189 distances, 6 intra-residue NOEs were removed as described above, and RGUA H1' 3 RCYT H6 uni-dir 5.01 was duplicated. The experimental error was set to 15%. After a preliminary refinement round we found it difficult to refine the simulation so as to match the following eNOE: C13_H5;C13_H5'';G12_H5'';C13_H5; #\n",
    "C5_H5;C5_H5''; A4_H62;U11_H3; A4_H61;U11_H3; C5_H4';C5_H5; U7_H5'';G9_H1. Since these eNOEs have a high value of sigma fit, they were removed from the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Found 177 pairs out of 177\n",
      "# Found 177 pairs out of 177\n",
      "# Found 177 pairs out of 177\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels,vals = read_exp(\"data/exp/set_A/eNOE_unidir.exp.dat\")\n",
    "\n",
    "\n",
    "top = \"data/PDB/2koc_gmx.pdb\"\n",
    "traj = \"data/traj_temp_f_0.xtc\"\n",
    "#######################\n",
    "md_trj = md.load(traj,top=top)\n",
    "pairs = get_idxs(labels,md_trj.topology)\n",
    "# convert to Angstrom\n",
    "dists_md = 10*md.compute_distances(md_trj,pairs)\n",
    "# write to file \n",
    "write(dists_md,\"data/calc/set_A/eNOE_unidir.calc.dat\")\n",
    "\n",
    "pdbs = [\"2koc\",\"6by5\"]\n",
    "dists_pdbs = []\n",
    "for  p in pdbs:\n",
    "    top = \"data/PDB/%s.pdb\" % p \n",
    "    traj = \"data/PDB/%s.pdb\" % p \n",
    "    md_trj = md.load(traj,top=top)\n",
    "    pairs = get_idxs(labels,md_trj.topology)\n",
    "    dists = 10.0*md.compute_distances(md_trj,pairs)\n",
    "    write(dists,\"data/calc/set_A/%s.eNOE_unidir.calc.dat\" %p)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gn-eNOE\n",
    "From 88 datapoints, 9 were removed and 5 RCYT H5\" 5 RCYT H5, 13 RCYT H2' 13 RCYT H5 were duplicated, resulting in 77 upper-limits distances. The experimental error was set to 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Found 84 pairs out of 84\n",
      "# Found 84 pairs out of 84\n",
      "# Found 84 pairs out of 84\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels,vals = read_exp(\"data/exp/set_A/gn_eNOE.exp.dat\")\n",
    "top = \"data/PDB/2koc_gmx.pdb\"\n",
    "traj = \"data/traj_temp_f_0.xtc\"\n",
    "#######################\n",
    "md_trj = md.load(traj,top=top)\n",
    "pairs = get_idxs(labels,md_trj.topology)\n",
    "# convert to Angstrom\n",
    "dists_md = 10*md.compute_distances(md_trj,pairs)\n",
    "# write to file \n",
    "write(dists_md,\"data/calc/set_A/gn_eNOE.calc.dat\")\n",
    "\n",
    "pdbs = [\"2koc\",\"6by5\"]\n",
    "dists_pdbs = []\n",
    "for  p in pdbs:\n",
    "    top = \"data/PDB/%s.pdb\" % p \n",
    "    traj = \"data/PDB/%s.pdb\" % p \n",
    "    md_trj = md.load(traj,top=top)\n",
    "    pairs = get_idxs(labels,md_trj.topology)\n",
    "    dists = 10.0*md.compute_distances(md_trj,pairs)\n",
    "    write(dists,\"data/calc/set_A/%s.gn_eNOE.calc.dat\" %p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset B\n",
    "Data taken from the study “High-Resolution NMR Structure of a RNA model system: the 14mer cUUCGg tetraloop hairpin RNA“ and corresponding PDB structure 2KOC. \n",
    "\n",
    "## NOE\n",
    "We sourced the 251 unambigous NOE data from the .mr restraint file deposited on the PDB. Experimental error was calculated as $\\sigma = (rmax-rmin)/2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Found 251 pairs out of 251\n",
      "# Found 251 pairs out of 251\n",
      "# Found 251 pairs out of 251\n"
     ]
    }
   ],
   "source": [
    "labels,vals = read_exp(\"data/exp/set_B/NOE.exp.dat\")\n",
    "\n",
    "#######################\n",
    "top = \"data/PDB/2koc_gmx.pdb\"\n",
    "traj = \"data/traj_temp_f_0.xtc\"\n",
    "md_trj = md.load(traj,top=top)\n",
    "pairs = get_idxs(labels,md_trj.topology)\n",
    "# convert to Angstrom\n",
    "dists_md = 10*md.compute_distances(md_trj,pairs)\n",
    "# write to file \n",
    "write(dists_md,\"data/calc/set_B/NOE.calc.dat\")\n",
    "\n",
    "pdbs = [\"2koc\",\"6by5\"]\n",
    "dists_pdbs = []\n",
    "for  p in pdbs:\n",
    "    top = \"data/PDB/%s.pdb\" % p \n",
    "    traj = \"data/PDB/%s.pdb\" % p \n",
    "    md_trj = md.load(traj,top=top)\n",
    "    pairs = get_idxs(labels,md_trj.topology)\n",
    "    dists = 10.0*md.compute_distances(md_trj,pairs)\n",
    "    write(dists,\"data/calc/set_B/%s.NOE.calc.dat\" %p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalar couplings\n",
    "\n",
    "Available 3J couplings relative to angles\n",
    "- 1H5-P, 2H5-P, C4-P (angle $\\beta$). Data for residue 1 are omitted because P is not present at the 5' end in simulations.\n",
    "- H3-P, C4-P(+1) (angle $\\epsilon$). Data for C2-P are not used because I could not find valid Karplus relationships.\n",
    "- 2H5H4, 1H5H4 (angle $\\gamma$).Data for C4-1H5/2H5 are not used because I could not find valid Karplus relationships.\n",
    "- H1'-H2', H2'-H3', H3'-H4' for the sugar.\n",
    "The error was taken 1.5HZ for all data.  In total, there are 96 scalar couplings. For calculating the scalar coupling from structure we used the Karplus relationship as defined in [baRNAba](https://github.com/srnas/barnaba)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read experimental data\n",
    "import barnaba as bb\n",
    "from barnaba import definitions\n",
    "jj = [l for l in (definitions.couplings_idx)]\n",
    "exp = []\n",
    "dd = []\n",
    "for line in open(\"data/exp/set_B/J3.exp.dat\"):\n",
    "    if(\"#\" not in line):\n",
    "        a = line.split()[0].split(\"-\")[0]\n",
    "        try: a = int(a)\n",
    "        except: a = int(a[1:])\n",
    "        b = line.split()[0].split(\"-\")[1]\n",
    "        dd.append(\"%d-%s\" % (a,b))\n",
    "        \n",
    "        exp.append([float(x) for x in line.split()[1:]])\n",
    "exp = np.array(exp)\n",
    "\n",
    "jjr = []\n",
    "for  c in range(14):\n",
    "    for j in jj:\n",
    "        jjr.append(\"%d-%s\" % (c+1,j))\n",
    "idxs = [jjr.index(el) for el in dd]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Loading data/traj_temp_f_0.xtc \n",
      "# Loading data/PDB/2koc.pdb \n",
      "# Loading data/PDB/6by5.pdb \n"
     ]
    }
   ],
   "source": [
    "# calculate scalar couplings for trajectory and write to file\n",
    "top = \"data/PDB/2koc_gmx.pdb\"\n",
    "native = \"data/PDB/2koc_gmx.pdb\"\n",
    "traj = \"data/traj_temp_f_0.xtc\"\n",
    "\n",
    "couplings,res = bb.jcouplings(traj,topology=top) \n",
    "data = couplings[:,:,:].reshape(-1,len(jjr))[:,idxs]\n",
    "write(data,\"data/calc/set_B/J3.calc.dat\")\n",
    "\n",
    "couplings_2koc,res_2koc = bb.jcouplings(\"data/PDB/2koc.pdb\",topology=\"data/PDB/2koc.pdb\")\n",
    "data_2koc = couplings_2koc[:,:,:].reshape(-1,len(jjr))[:,idxs]\n",
    "write(data_2koc,\"data/calc/set_B/2koc.J3.calc.dat\")\n",
    "\n",
    "couplings_6by5,res_6by5 = bb.jcouplings(\"data/PDB/6by5.pdb\",topology=\"data/PDB/6by5.pdb\")\n",
    "data_6by5 = couplings_6by5[:,:,:].reshape(-1,len(jjr))[:,idxs]\n",
    "write(data_6by5,\"data/calc/set_B/6by5.J3.calc.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross-correlated relaxation rates\n",
    "Cross-correlated relaxation rates are calculated using the script available on [github](https://github.com/sbottaro/CCRR). Here we just format the data to make them compatible with the reweighting script.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# read experimental data \n",
    "df_exp = pd.read_csv(\"data/exp/set_B/CCRR.exp.dat\",sep=\"\\s+\",names=[\"label\",\"exp_val\"],comment=\"#\")\n",
    "\n",
    "\n",
    "# read 6BY5\n",
    "df_calc_6by5 = pd.read_csv(\"data/calc/set_B/6by5_ccrr_calc.dat\",sep=\"\\s+\").transpose()\n",
    "# merge\n",
    "df_calc_6by5_ok = df_exp.merge(df_calc_6by5,left_on=\"label\",right_index=True,how=\"left\")\n",
    "# write to file\n",
    "df_calc_6by5_ok = (df_calc_6by5_ok[list(df_calc_6by5_ok.columns[2:])]).transpose()\n",
    "df_calc_6by5_ok.to_csv(\"data/calc/set_B/6by5.CCRR.calc.dat\",sep=\" \",float_format='%8.4e',header=False)\n",
    "\n",
    "\n",
    "# read 2KOC\n",
    "df_calc_2koc = pd.read_csv(\"data/calc/set_B/2koc_ccrr_calc.dat\",sep=\"\\s+\").transpose()\n",
    "# merge\n",
    "df_calc_2koc_ok = df_exp.merge(df_calc_2koc,left_on=\"label\",right_index=True,how=\"left\")\n",
    "# write to file\n",
    "df_calc_2koc_ok = (df_calc_2koc_ok[list(df_calc_2koc_ok.columns[2:])]).transpose()\n",
    "df_calc_2koc_ok.to_csv(\"data/calc/set_B/2koc.CCRR.calc.dat\",sep=\" \",float_format='%8.4e',header=False)\n",
    "\n",
    "\n",
    "# read 2KOC\n",
    "df_calc = pd.read_csv(\"data/calc/set_B/traj_temp_f_0_ccrr_calc.dat\",sep=\"\\s+\").transpose()\n",
    "# merge\n",
    "df_calc_ok = df_exp.merge(df_calc,left_on=\"label\",right_index=True,how=\"left\")\n",
    "# write to file\n",
    "df_calc_ok = (df_calc_ok[list(df_calc_ok.columns[2:])]).transpose()\n",
    "df_calc_ok.to_csv(\"data/calc/set_B/CCRR.calc.dat\",sep=\" \",float_format='%8.4e',header=False)\n",
    "\n",
    "#df_calc_2koc_ok = df_exp.merge(df_calc_2koc,left_on=\"label\",right_index=True,how=\"left\")\n",
    "\n",
    "#(df[[\"label\",\"exp_val\",0]]).to_csv(\"2koc_ccrr.dat\",sep=\" \",float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDC\n",
    "\n",
    "\n",
    "32 RDC were taken from the .mr restraint file deposited on the PDB.\n",
    "For each samples, RDC are calculated using the software [pales](https://spin.niddk.nih.gov/bax/software/PALES/)\n",
    "\n",
    "    `pales -pdb sample.pdb -inD exp/rdc_set_c_bme.dat -outD outfile -H -pf1 -wv 0.022`\n",
    "    \n",
    "\n",
    "The ensemble average is then rescaled globally by a factor \n",
    "\n",
    "$L = \\sum_i \\text{exp}_i \\text{avg}_i/\\sum_i \\text{avg}_i \\text{avg}_i$\n",
    "\n",
    "Where the sum runs over the experimental data and $\\text{avg}_i = \\sum_j w_j F(x_j)$\n",
    "is the pales prediction $F(x_j)$ averaged over the configurations $x_j$.\n",
    "The error sigma was set to 1Hz. \n",
    "\n",
    "# Dataset C\n",
    "\n",
    "RDC taken from \"Simultaneous NMR characterisation of multiple minima in the free energy landscape of an RNA UUCG tetraloop\" are devided in two sub-datasets, RDC_1 ( 39 datapoints) and RDC_2 (14 datapoints). Back-calculation was performed as in set B. The experimental error was set to 1.4Hz (RDC_1) and 2.2 Hz (RDC_2) as described in the original paper.\n",
    "\n",
    "\n",
    "\n",
    "# Dataset D\n",
    "\n",
    "Solvent PRE data were obtained from the authors of the study  \"RNA structure refinement using NMR solvent accessibility data. Sci Rep. 2017; 7: 5393.\" The back-calculation of experimental measure from structure was performed using the program from Chun Tang's lab, available [here](http://www.tanglab.org/resources/programs) using a probe radius of 0.35 nm.\n",
    "\n",
    "Since RDC and sPRE calculations both require PDB files, we back calculate RDC in dataset B, dataset C and sPRE  in the code below (att! takes a looong time).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "traj = \"data/traj_temp_f_0.xtc\"\n",
    "top = \"data/PDB/2koc_gmx.pdb\"\n",
    "atoms = [\"H1\",\"H2\",\"H3\",\"H41\",\"H42\",\"H61\",\"H62\",\"H5\",\"H21\",\"H22\",\"H3'\",\"H4'\",\"1H5'\",\"2H5'\",\"1H2'\",\"H1'\",\"H6\",\"H8\"]\n",
    "pales_cmd = \"/home/sbottaro/Software/pales/linux/pales\"\n",
    "\n",
    "md_trj = md.load(traj,top=top)\n",
    "\n",
    "\n",
    "def do(i):\n",
    "    pdb=\"data/PDB/sample_%08d.pdb\" % i\n",
    "    out_B=\"data/calc/set_B/sample_%08d\" % i\n",
    "    out_C1=\"data/calc/set_C/sample_%08d_1\" % i\n",
    "    out_C2=\"data/calc/set_C/sample_%08d_2\" % i\n",
    "    out_D=\"data/calc/set_D/sample_%08d\" % i\n",
    "    md_trj[i].save(pdb)\n",
    "    cmdB = \"%s -pdb %s -inD data/exp/set_B/RDC.pales.exp.dat -outD %s -H -pf1 -wv 0.022\" % (pales_cmd,pdb,out_B)\n",
    "    cmdC1 = \"%s -pdb %s -inD data/exp/set_C/RDC1_MD.pales.exp.dat -outD %s -H -pf1 -wv 0.022\" % (pales_cmd,pdb,out_C1)\n",
    "    cmdC2 = \"%s -pdb %s -inD data/exp/set_C/RDC2_MD.pales.exp.dat -outD %s -H -pf1 -wv 0.022\" % (pales_cmd,pdb,out_C2)\n",
    "    os.system(cmdB)\n",
    "    os.system(cmdC1)\n",
    "    os.system(cmdC2)\n",
    "    #for at in atoms:\n",
    "    #    ee = at.replace(\"'\",\"p\")\n",
    "    #    cmdD = \"data/script/spre.x %s 3.5 0 \\\"%s\\\" > %s_%s\"   % (pdb,at,out_D,ee)\n",
    "    #    os.system(cmdD)\n",
    "    \n",
    "#oo = Parallel(n_jobs=40)(delayed(do)(i) for i in range(len(md_trj)))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now do the above again for PDB files. Note that H naming is different in RDC1 and RDC2\n",
    "\n",
    "lista = glob.glob(\"data/PDB/[2-6]*.pdb\")\n",
    "for pdb in lista:\n",
    "    ii = pdb.split(\"/\")[-1].split(\".pdb\")[0]\n",
    "    out_B=\"data/calc/set_B/%s\" % ii\n",
    "    out_C1=\"data/calc/set_C/%s_1\" % ii\n",
    "    out_C2=\"data/calc/set_C/%s_2\" % ii\n",
    "    out_D=\"data/calc/set_D/%s\" % ii\n",
    "\n",
    "    cmdB = \"%s -pdb %s -inD data/exp/set_B/RDC.pales.exp.dat -outD %s -H -pf1 -wv 0.022\" % (pales_cmd,pdb,out_B)\n",
    "    cmdC1 = \"%s -pdb %s -inD data/exp/set_C/RDC1.pales.exp.dat -outD %s -H -pf1 -wv 0.022\" % (pales_cmd,pdb,out_C1)\n",
    "    cmdC2 = \"%s -pdb %s -inD data/exp/set_C/RDC2.pales.exp.dat -outD %s -H -pf1 -wv 0.022\" % (pales_cmd,pdb,out_C2)\n",
    "    os.system(cmdB)\n",
    "    os.system(cmdC1)\n",
    "    os.system(cmdC2)\n",
    "    #for at in atoms:\n",
    "    #    ee = at.replace(\"'\",\"p\")\n",
    "    #    cmdD = \"data/script/spre.x %s 3.5 0 \\\"%s\\\" > %s_%s\"   % (pdb,at,out_D,ee)\n",
    "    #    os.system(cmdD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for el in sample*; do echo -n ${el:7:9} >> data/calc/set_B/RDC.calc.dat; tail -n 32 $el | awk '{printf \"  \" $9 }END{printf \"\\n\"}' >> data/calc/set_B/RDC.calc.dat ;done\n",
      "#\r\n"
     ]
    }
   ],
   "source": [
    "# bash code below to reformat the output\n",
    "\n",
    "# for el in sample*; do echo -n ${el:7:9} >> RDC.calc.dat; tail -n 32 $el | awk '{printf \"  \" $9 }END{printf \"\\n\"}' >> RDC.calc.dat ;done\"\n",
    "# for el in sample*_1; do echo -n ${el:7:8} >> RDC1.calc.dat; tail -n 39 $el | awk '{printf \"  \" $9 }END{printf \"\\n\"}' >> RDC1.calc.dat ;done\n",
    "# for el in sample*_2; do echo -n ${el:7:8} >> RDC2.calc.dat; tail -n 14 $el | awk '{printf \"  \" $9 }END{printf \"\\n\"}' >> RDC2.calc.dat ;done\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
